{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VqEpGyyyGE1Z",
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "## Solving the linear regression problem with gradient descent\n",
    "\n",
    "Today we rewise the linear regression algorithm and it's gradient solution.\n",
    "\n",
    "Your main goal will be to __derive and implement the gradient of MSE, MAE, L1 and L2 regularization terms__ respectively in general __vector form__ (when both single observation $\\mathbf{x}_i$ and corresponding target value $\\mathbf{y}_i$ are vectors).\n",
    "\n",
    "This techniques will be useful later in Deep Learning module of our course as well.\n",
    "\n",
    "We will work with [Boston housing prices dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) subset, which have been preprocessed for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If you are using Google Colab, uncomment the next lines to download `loss_and_derivatives.py` and `boston_subset.json`\n",
    "You can open and change downloaded `.py` files in Colab using the \"Files\" sidebar on the left.\n",
    "'''\n",
    "# !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/basic_f20/homeworks_basic/assignment0_02_Lin_reg/loss_and_derivatives.py\n",
    "# !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/basic_f20/homeworks_basic/assignment0_02_Lin_reg/boston_subset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lQUR89nGE1f"
   },
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGf3ShTNGE1q"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('boston_subset.json', 'r') as iofile:\n",
    "    dataset = json.load(iofile)\n",
    "feature_matrix = np.array(dataset['data'])\n",
    "targets = np.array(dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [[0.231, 0.49800000000000005],\n",
       "  [0.7070000000000001, 0.914],\n",
       "  [0.7070000000000001, 0.403],\n",
       "  [0.21800000000000003, 0.294],\n",
       "  [0.21800000000000003, 0.533],\n",
       "  [0.21800000000000003, 0.521],\n",
       "  [0.787, 1.2429999999999999],\n",
       "  [0.787, 1.9149999999999998],\n",
       "  [0.787, 2.993],\n",
       "  [0.787, 1.7100000000000002],\n",
       "  [0.787, 2.045],\n",
       "  [0.787, 1.327],\n",
       "  [0.787, 1.5710000000000002],\n",
       "  [0.8140000000000001, 0.826],\n",
       "  [0.8140000000000001, 1.026],\n",
       "  [0.8140000000000001, 0.8470000000000001],\n",
       "  [0.8140000000000001, 0.658],\n",
       "  [0.8140000000000001, 1.467],\n",
       "  [0.8140000000000001, 1.169],\n",
       "  [0.8140000000000001, 1.128],\n",
       "  [0.8140000000000001, 2.102],\n",
       "  [0.8140000000000001, 1.383],\n",
       "  [0.8140000000000001, 1.8719999999999999],\n",
       "  [0.8140000000000001, 1.988],\n",
       "  [0.8140000000000001, 1.6300000000000001],\n",
       "  [0.8140000000000001, 1.6510000000000002],\n",
       "  [0.8140000000000001, 1.481],\n",
       "  [0.8140000000000001, 1.7280000000000002],\n",
       "  [0.8140000000000001, 1.28],\n",
       "  [0.8140000000000001, 1.198],\n",
       "  [0.8140000000000001, 2.2600000000000002],\n",
       "  [0.8140000000000001, 1.3039999999999998],\n",
       "  [0.8140000000000001, 2.771],\n",
       "  [0.8140000000000001, 1.8350000000000002],\n",
       "  [0.8140000000000001, 2.034],\n",
       "  [0.596, 0.968],\n",
       "  [0.596, 1.141],\n",
       "  [0.596, 0.877],\n",
       "  [0.596, 1.0130000000000001],\n",
       "  [0.29500000000000004, 0.43200000000000005],\n",
       "  [0.29500000000000004, 0.198],\n",
       "  [0.6910000000000001, 0.484],\n",
       "  [0.6910000000000001, 0.581],\n",
       "  [0.6910000000000001, 0.744],\n",
       "  [0.6910000000000001, 0.9550000000000001],\n",
       "  [0.6910000000000001, 1.0210000000000001],\n",
       "  [0.6910000000000001, 1.415],\n",
       "  [0.6910000000000001, 1.8800000000000001],\n",
       "  [0.6910000000000001, 3.081],\n",
       "  [0.6910000000000001, 1.6199999999999999],\n",
       "  [0.564, 1.345],\n",
       "  [0.564, 0.943],\n",
       "  [0.564, 0.528],\n",
       "  [0.564, 0.843],\n",
       "  [0.4, 1.48],\n",
       "  [0.122, 0.481],\n",
       "  [0.074, 0.577],\n",
       "  [0.132, 0.395],\n",
       "  [0.513, 0.686],\n",
       "  [0.513, 0.922],\n",
       "  [0.513, 1.315],\n",
       "  [0.513, 1.444],\n",
       "  [0.513, 0.673],\n",
       "  [0.513, 0.95],\n",
       "  [0.13799999999999998, 0.805],\n",
       "  [0.337, 0.46699999999999997],\n",
       "  [0.337, 1.024],\n",
       "  [0.607, 0.8099999999999999],\n",
       "  [0.607, 1.309],\n",
       "  [0.607, 0.8789999999999999],\n",
       "  [1.081, 0.6719999999999999],\n",
       "  [1.081, 0.9880000000000001],\n",
       "  [1.081, 0.5519999999999999],\n",
       "  [1.081, 0.754],\n",
       "  [1.283, 0.678],\n",
       "  [1.283, 0.8939999999999999],\n",
       "  [1.283, 1.197],\n",
       "  [1.283, 1.027],\n",
       "  [1.283, 1.234],\n",
       "  [1.283, 0.9099999999999999],\n",
       "  [0.48600000000000004, 0.529],\n",
       "  [0.48600000000000004, 0.722],\n",
       "  [0.48600000000000004, 0.6719999999999999],\n",
       "  [0.48600000000000004, 0.751],\n",
       "  [0.449, 0.962],\n",
       "  [0.449, 0.653],\n",
       "  [0.449, 1.286],\n",
       "  [0.449, 0.844],\n",
       "  [0.341, 0.55],\n",
       "  [0.341, 0.5700000000000001],\n",
       "  [0.341, 0.881],\n",
       "  [0.341, 0.82],\n",
       "  [1.504, 0.8160000000000001],\n",
       "  [1.504, 0.621],\n",
       "  [1.504, 1.059],\n",
       "  [0.28900000000000003, 0.665],\n",
       "  [0.28900000000000003, 1.134],\n",
       "  [0.28900000000000003, 0.421],\n",
       "  [0.28900000000000003, 0.357],\n",
       "  [0.28900000000000003, 0.619],\n",
       "  [0.8560000000000001, 0.942],\n",
       "  [0.8560000000000001, 0.767],\n",
       "  [0.8560000000000001, 1.0630000000000002],\n",
       "  [0.8560000000000001, 1.3439999999999999],\n",
       "  [0.8560000000000001, 1.233],\n",
       "  [0.8560000000000001, 1.6469999999999998],\n",
       "  [0.8560000000000001, 1.866],\n",
       "  [0.8560000000000001, 1.409],\n",
       "  [0.8560000000000001, 1.2269999999999999],\n",
       "  [0.8560000000000001, 1.5550000000000002],\n",
       "  [0.8560000000000001, 1.3],\n",
       "  [1.001, 1.016],\n",
       "  [1.001, 1.621],\n",
       "  [1.001, 1.709],\n",
       "  [1.001, 1.045],\n",
       "  [1.001, 1.576],\n",
       "  [1.001, 1.204],\n",
       "  [1.001, 1.03],\n",
       "  [1.001, 1.537],\n",
       "  [1.001, 1.361],\n",
       "  [2.565, 1.4369999999999998],\n",
       "  [2.565, 1.427],\n",
       "  [2.565, 1.793],\n",
       "  [2.565, 2.541],\n",
       "  [2.565, 1.7579999999999998],\n",
       "  [2.565, 1.481],\n",
       "  [2.565, 2.726],\n",
       "  [2.189, 1.719],\n",
       "  [2.189, 1.5390000000000001],\n",
       "  [2.189, 1.834],\n",
       "  [2.189, 1.26],\n",
       "  [2.189, 1.226],\n",
       "  [2.189, 1.1119999999999999],\n",
       "  [2.189, 1.503],\n",
       "  [2.189, 1.7309999999999999],\n",
       "  [2.189, 1.6960000000000002],\n",
       "  [2.189, 1.69],\n",
       "  [2.189, 1.459],\n",
       "  [2.189, 2.132],\n",
       "  [2.189, 1.846],\n",
       "  [2.189, 2.416],\n",
       "  [2.189, 3.441],\n",
       "  [1.9579999999999997, 2.682],\n",
       "  [1.9579999999999997, 2.6420000000000003],\n",
       "  [1.9579999999999997, 2.929],\n",
       "  [1.9579999999999997, 2.7800000000000002],\n",
       "  [1.9579999999999997, 1.6649999999999998],\n",
       "  [1.9579999999999997, 2.9530000000000003],\n",
       "  [1.9579999999999997, 2.832],\n",
       "  [1.9579999999999997, 2.145],\n",
       "  [1.9579999999999997, 1.41],\n",
       "  [1.9579999999999997, 1.3279999999999998],\n",
       "  [1.9579999999999997, 1.212],\n",
       "  [1.9579999999999997, 1.579],\n",
       "  [1.9579999999999997, 1.512],\n",
       "  [1.9579999999999997, 1.502],\n",
       "  [1.9579999999999997, 1.614],\n",
       "  [1.9579999999999997, 0.45899999999999996],\n",
       "  [1.9579999999999997, 0.643],\n",
       "  [1.9579999999999997, 0.739],\n",
       "  [1.9579999999999997, 0.55],\n",
       "  [1.9579999999999997, 0.173],\n",
       "  [1.9579999999999997, 0.192],\n",
       "  [1.9579999999999997, 0.33199999999999996],\n",
       "  [1.9579999999999997, 1.1640000000000001],\n",
       "  [1.9579999999999997, 0.9810000000000001],\n",
       "  [1.9579999999999997, 0.37],\n",
       "  [1.9579999999999997, 1.214],\n",
       "  [1.9579999999999997, 1.1099999999999999],\n",
       "  [1.9579999999999997, 1.1320000000000001],\n",
       "  [1.9579999999999997, 1.443],\n",
       "  [1.9579999999999997, 1.2029999999999998],\n",
       "  [0.40499999999999997, 1.4689999999999999],\n",
       "  [0.40499999999999997, 0.9039999999999999],\n",
       "  [0.40499999999999997, 0.9640000000000001],\n",
       "  [0.40499999999999997, 0.533],\n",
       "  [0.40499999999999997, 1.011],\n",
       "  [0.40499999999999997, 0.629],\n",
       "  [0.40499999999999997, 0.692],\n",
       "  [0.246, 0.504],\n",
       "  [0.246, 0.756],\n",
       "  [0.246, 0.945],\n",
       "  [0.246, 0.48200000000000004],\n",
       "  [0.246, 0.568],\n",
       "  [0.246, 1.3980000000000001],\n",
       "  [0.246, 1.315],\n",
       "  [0.246, 0.445],\n",
       "  [0.344, 0.6679999999999999],\n",
       "  [0.344, 0.45599999999999996],\n",
       "  [0.344, 0.5389999999999999],\n",
       "  [0.344, 0.51],\n",
       "  [0.344, 0.46900000000000003],\n",
       "  [0.344, 0.28700000000000003],\n",
       "  [0.29300000000000004, 0.503],\n",
       "  [0.29300000000000004, 0.438],\n",
       "  [0.046, 0.29700000000000004],\n",
       "  [0.152, 0.40800000000000003],\n",
       "  [0.152, 0.861],\n",
       "  [0.152, 0.662],\n",
       "  [0.147, 0.45599999999999996],\n",
       "  [0.147, 0.445],\n",
       "  [0.20299999999999999, 0.743],\n",
       "  [0.20299999999999999, 0.311],\n",
       "  [0.268, 0.381],\n",
       "  [0.268, 0.288],\n",
       "  [1.059, 1.087],\n",
       "  [1.059, 1.097],\n",
       "  [1.059, 1.8059999999999998],\n",
       "  [1.059, 1.466],\n",
       "  [1.059, 2.309],\n",
       "  [1.059, 1.7269999999999999],\n",
       "  [1.059, 2.398],\n",
       "  [1.059, 1.6030000000000002],\n",
       "  [1.059, 0.9380000000000001],\n",
       "  [1.059, 2.955],\n",
       "  [1.059, 0.9470000000000001],\n",
       "  [1.389, 1.351],\n",
       "  [1.389, 0.969],\n",
       "  [1.389, 1.7920000000000003],\n",
       "  [1.389, 1.05],\n",
       "  [0.62, 0.9710000000000001],\n",
       "  [0.62, 2.146],\n",
       "  [0.62, 0.993],\n",
       "  [0.62, 0.76],\n",
       "  [0.62, 0.414],\n",
       "  [0.62, 0.46299999999999997],\n",
       "  [0.62, 0.313],\n",
       "  [0.62, 0.636],\n",
       "  [0.62, 0.392],\n",
       "  [0.62, 0.376],\n",
       "  [0.62, 1.165],\n",
       "  [0.62, 0.525],\n",
       "  [0.62, 0.24700000000000003],\n",
       "  [0.62, 0.395],\n",
       "  [0.62, 0.805],\n",
       "  [0.62, 1.088],\n",
       "  [0.62, 0.954],\n",
       "  [0.62, 0.47300000000000003],\n",
       "  [0.493, 0.636],\n",
       "  [0.493, 0.737],\n",
       "  [0.493, 1.1380000000000001],\n",
       "  [0.493, 1.24],\n",
       "  [0.493, 1.122],\n",
       "  [0.493, 0.519],\n",
       "  [0.5860000000000001, 1.25],\n",
       "  [0.5860000000000001, 1.846],\n",
       "  [0.5860000000000001, 0.916],\n",
       "  [0.5860000000000001, 1.0150000000000001],\n",
       "  [0.5860000000000001, 0.952],\n",
       "  [0.5860000000000001, 0.6559999999999999],\n",
       "  [0.5860000000000001, 0.5900000000000001],\n",
       "  [0.5860000000000001, 0.359],\n",
       "  [0.5860000000000001, 0.353],\n",
       "  [0.5860000000000001, 0.354],\n",
       "  [0.364, 0.657],\n",
       "  [0.364, 0.925],\n",
       "  [0.375, 0.311],\n",
       "  [0.397, 0.512],\n",
       "  [0.397, 0.779],\n",
       "  [0.397, 0.6900000000000001],\n",
       "  [0.397, 0.959],\n",
       "  [0.397, 0.726],\n",
       "  [0.397, 0.591],\n",
       "  [0.397, 1.125],\n",
       "  [0.397, 0.8099999999999999],\n",
       "  [0.397, 1.045],\n",
       "  [0.397, 1.4789999999999999],\n",
       "  [0.397, 0.744],\n",
       "  [0.397, 0.316],\n",
       "  [0.696, 1.365],\n",
       "  [0.696, 1.3],\n",
       "  [0.696, 0.659],\n",
       "  [0.696, 0.773],\n",
       "  [0.696, 0.658],\n",
       "  [0.641, 0.353],\n",
       "  [0.641, 0.298],\n",
       "  [0.641, 0.605],\n",
       "  [0.641, 0.41600000000000004],\n",
       "  [0.641, 0.7190000000000001],\n",
       "  [0.333, 0.485],\n",
       "  [0.333, 0.376],\n",
       "  [0.333, 0.45899999999999996],\n",
       "  [0.333, 0.301],\n",
       "  [0.121, 0.316],\n",
       "  [0.29700000000000004, 0.7849999999999999],\n",
       "  [0.225, 0.8230000000000001],\n",
       "  [0.176, 1.293],\n",
       "  [0.532, 0.714],\n",
       "  [0.532, 0.76],\n",
       "  [0.532, 0.951],\n",
       "  [0.495, 0.333],\n",
       "  [0.495, 0.356],\n",
       "  [0.495, 0.47000000000000003],\n",
       "  [1.392, 0.858],\n",
       "  [1.392, 1.04],\n",
       "  [1.392, 0.627],\n",
       "  [1.392, 0.739],\n",
       "  [1.392, 1.584],\n",
       "  [0.22400000000000003, 0.497],\n",
       "  [0.22400000000000003, 0.47400000000000003],\n",
       "  [0.22400000000000003, 0.607],\n",
       "  [0.609, 0.95],\n",
       "  [0.609, 0.867],\n",
       "  [0.609, 0.48600000000000004],\n",
       "  [0.21800000000000003, 0.693],\n",
       "  [0.21800000000000003, 0.893],\n",
       "  [0.21800000000000003, 0.647],\n",
       "  [0.21800000000000003, 0.753],\n",
       "  [0.99, 0.454],\n",
       "  [0.99, 0.9970000000000001],\n",
       "  [0.99, 1.264],\n",
       "  [0.99, 0.5980000000000001],\n",
       "  [0.99, 1.1720000000000002],\n",
       "  [0.99, 0.79],\n",
       "  [0.99, 0.9279999999999999],\n",
       "  [0.99, 1.15],\n",
       "  [0.99, 1.8329999999999997],\n",
       "  [0.99, 1.5939999999999999],\n",
       "  [0.99, 1.036],\n",
       "  [0.99, 1.2730000000000001],\n",
       "  [0.738, 0.72],\n",
       "  [0.738, 0.687],\n",
       "  [0.738, 0.77],\n",
       "  [0.738, 1.174],\n",
       "  [0.738, 0.612],\n",
       "  [0.738, 0.508],\n",
       "  [0.738, 0.615],\n",
       "  [0.738, 1.279],\n",
       "  [0.324, 0.9970000000000001],\n",
       "  [0.324, 0.734],\n",
       "  [0.324, 0.909],\n",
       "  [0.606, 1.2429999999999999],\n",
       "  [0.606, 0.783],\n",
       "  [0.519, 0.568],\n",
       "  [0.519, 0.675],\n",
       "  [0.519, 0.8009999999999999],\n",
       "  [0.519, 0.9800000000000001],\n",
       "  [0.519, 1.056],\n",
       "  [0.519, 0.851],\n",
       "  [0.519, 0.974],\n",
       "  [0.519, 0.9289999999999999],\n",
       "  [0.152, 0.549],\n",
       "  [0.189, 0.865],\n",
       "  [0.378, 0.718],\n",
       "  [0.378, 0.461],\n",
       "  [0.43899999999999995, 1.053],\n",
       "  [0.43899999999999995, 1.267],\n",
       "  [0.41500000000000004, 0.636],\n",
       "  [0.20099999999999998, 0.599],\n",
       "  [0.125, 0.589],\n",
       "  [0.125, 0.5980000000000001],\n",
       "  [0.16899999999999998, 0.549],\n",
       "  [0.16899999999999998, 0.779],\n",
       "  [0.202, 0.45],\n",
       "  [0.191, 0.805],\n",
       "  [0.191, 0.557],\n",
       "  [1.81, 1.7600000000000002],\n",
       "  [1.81, 1.327],\n",
       "  [1.81, 1.1480000000000001],\n",
       "  [1.81, 1.267],\n",
       "  [1.81, 0.779],\n",
       "  [1.81, 1.419],\n",
       "  [1.81, 1.019],\n",
       "  [1.81, 1.464],\n",
       "  [1.81, 0.529],\n",
       "  [1.81, 0.712],\n",
       "  [1.81, 1.4],\n",
       "  [1.81, 1.333],\n",
       "  [1.81, 0.32599999999999996],\n",
       "  [1.81, 0.373],\n",
       "  [1.81, 0.296],\n",
       "  [1.81, 0.953],\n",
       "  [1.81, 0.8880000000000001],\n",
       "  [1.81, 3.4770000000000003],\n",
       "  [1.81, 3.7969999999999997],\n",
       "  [1.81, 1.3439999999999999],\n",
       "  [1.81, 2.324],\n",
       "  [1.81, 2.1239999999999997],\n",
       "  [1.81, 2.369],\n",
       "  [1.81, 2.178],\n",
       "  [1.81, 1.721],\n",
       "  [1.81, 2.1079999999999997],\n",
       "  [1.81, 2.3600000000000003],\n",
       "  [1.81, 2.456],\n",
       "  [1.81, 3.0629999999999997],\n",
       "  [1.81, 3.081],\n",
       "  [1.81, 2.8280000000000003],\n",
       "  [1.81, 3.199],\n",
       "  [1.81, 3.0620000000000003],\n",
       "  [1.81, 2.085],\n",
       "  [1.81, 1.7109999999999999],\n",
       "  [1.81, 1.8760000000000001],\n",
       "  [1.81, 2.568],\n",
       "  [1.81, 1.517],\n",
       "  [1.81, 1.6350000000000002],\n",
       "  [1.81, 1.7120000000000002],\n",
       "  [1.81, 1.937],\n",
       "  [1.81, 1.9920000000000002],\n",
       "  [1.81, 3.059],\n",
       "  [1.81, 2.997],\n",
       "  [1.81, 2.677],\n",
       "  [1.81, 2.032],\n",
       "  [1.81, 2.0309999999999997],\n",
       "  [1.81, 1.9769999999999999],\n",
       "  [1.81, 2.738],\n",
       "  [1.81, 2.298]],\n",
       " 'target': [-9.360343933105469,\n",
       "  -11.760343933105467,\n",
       "  1.339656066894534,\n",
       "  0.03965606689452983,\n",
       "  2.839656066894534,\n",
       "  -4.6603439331054695,\n",
       "  -10.46034393310547,\n",
       "  -6.260343933105467,\n",
       "  -16.86034393310547,\n",
       "  -14.46034393310547,\n",
       "  -18.36034393310547,\n",
       "  -14.46034393310547,\n",
       "  -11.66034393310547,\n",
       "  -12.96034393310547,\n",
       "  -15.16034393310547,\n",
       "  -13.46034393310547,\n",
       "  -10.260343933105467,\n",
       "  -15.860343933105469,\n",
       "  -13.16034393310547,\n",
       "  -15.16034393310547,\n",
       "  -19.760343933105467,\n",
       "  -13.760343933105467,\n",
       "  -18.16034393310547,\n",
       "  -18.86034393310547,\n",
       "  -17.760343933105467,\n",
       "  -19.46034393310547,\n",
       "  -16.760343933105467,\n",
       "  -18.560343933105468,\n",
       "  -14.96034393310547,\n",
       "  -12.360343933105469,\n",
       "  -20.66034393310547,\n",
       "  -18.86034393310547,\n",
       "  -20.16034393310547,\n",
       "  -20.260343933105467,\n",
       "  -19.86034393310547,\n",
       "  -14.46034393310547,\n",
       "  -13.360343933105469,\n",
       "  -12.360343933105469,\n",
       "  -8.66034393310547,\n",
       "  -2.560343933105468,\n",
       "  1.5396560668945298,\n",
       "  -6.760343933105467,\n",
       "  -8.060343933105468,\n",
       "  -8.66034393310547,\n",
       "  -12.16034393310547,\n",
       "  -14.060343933105468,\n",
       "  -13.360343933105469,\n",
       "  -16.760343933105467,\n",
       "  -18.96034393310547,\n",
       "  -13.96034393310547,\n",
       "  -13.66034393310547,\n",
       "  -12.860343933105469,\n",
       "  -8.360343933105469,\n",
       "  -9.96034393310547,\n",
       "  -14.46034393310547,\n",
       "  2.03965606689453,\n",
       "  -8.66034393310547,\n",
       "  -1.7603439331054673,\n",
       "  -10.060343933105468,\n",
       "  -13.760343933105467,\n",
       "  -14.66034393310547,\n",
       "  -17.36034393310547,\n",
       "  -11.16034393310547,\n",
       "  -8.360343933105469,\n",
       "  -0.36034393310546875,\n",
       "  -9.860343933105469,\n",
       "  -13.96034393310547,\n",
       "  -11.360343933105469,\n",
       "  -15.96034393310547,\n",
       "  -12.46034393310547,\n",
       "  -9.16034393310547,\n",
       "  -11.66034393310547,\n",
       "  -10.560343933105468,\n",
       "  -9.96034393310547,\n",
       "  -9.260343933105467,\n",
       "  -11.96034393310547,\n",
       "  -13.360343933105469,\n",
       "  -12.560343933105468,\n",
       "  -12.16034393310547,\n",
       "  -13.060343933105468,\n",
       "  -5.360343933105469,\n",
       "  -9.46034393310547,\n",
       "  -8.560343933105468,\n",
       "  -10.46034393310547,\n",
       "  -9.46034393310547,\n",
       "  -6.760343933105467,\n",
       "  -10.860343933105469,\n",
       "  -11.16034393310547,\n",
       "  -9.760343933105467,\n",
       "  -4.6603439331054695,\n",
       "  -10.760343933105467,\n",
       "  -11.360343933105469,\n",
       "  -10.46034393310547,\n",
       "  -8.360343933105469,\n",
       "  -12.760343933105467,\n",
       "  -4.96034393310547,\n",
       "  -11.96034393310547,\n",
       "  5.339656066894534,\n",
       "  10.439656066894528,\n",
       "  -0.1603439331054659,\n",
       "  -5.860343933105469,\n",
       "  -6.860343933105469,\n",
       "  -14.760343933105467,\n",
       "  -14.060343933105468,\n",
       "  -13.260343933105467,\n",
       "  -13.860343933105469,\n",
       "  -13.860343933105469,\n",
       "  -12.96034393310547,\n",
       "  -13.560343933105468,\n",
       "  -13.96034393310547,\n",
       "  -11.66034393310547,\n",
       "  -10.560343933105468,\n",
       "  -14.560343933105468,\n",
       "  -14.66034393310547,\n",
       "  -14.860343933105469,\n",
       "  -15.060343933105468,\n",
       "  -12.16034393310547,\n",
       "  -14.16034393310547,\n",
       "  -12.96034393310547,\n",
       "  -14.060343933105468,\n",
       "  -11.360343933105469,\n",
       "  -13.060343933105468,\n",
       "  -12.860343933105469,\n",
       "  -16.060343933105468,\n",
       "  -14.560343933105468,\n",
       "  -11.96034393310547,\n",
       "  -17.66034393310547,\n",
       "  -17.16034393310547,\n",
       "  -15.360343933105469,\n",
       "  -19.060343933105468,\n",
       "  -14.16034393310547,\n",
       "  -13.760343933105467,\n",
       "  -10.360343933105469,\n",
       "  -14.96034393310547,\n",
       "  -17.760343933105467,\n",
       "  -15.260343933105467,\n",
       "  -15.96034393310547,\n",
       "  -16.260343933105467,\n",
       "  -20.060343933105468,\n",
       "  -15.560343933105468,\n",
       "  -19.36034393310547,\n",
       "  -18.96034393310547,\n",
       "  -19.96034393310547,\n",
       "  -17.760343933105467,\n",
       "  -21.560343933105468,\n",
       "  -19.560343933105468,\n",
       "  -17.760343933105467,\n",
       "  -18.760343933105467,\n",
       "  -15.560343933105468,\n",
       "  -17.96034393310547,\n",
       "  -11.860343933105469,\n",
       "  -13.760343933105467,\n",
       "  -18.060343933105468,\n",
       "  -13.96034393310547,\n",
       "  -16.36034393310547,\n",
       "  -17.760343933105467,\n",
       "  -20.260343933105467,\n",
       "  7.939656066894528,\n",
       "  -9.060343933105468,\n",
       "  -10.060343933105468,\n",
       "  -6.360343933105469,\n",
       "  16.63965606689453,\n",
       "  16.63965606689453,\n",
       "  16.63965606689453,\n",
       "  -10.66034393310547,\n",
       "  -8.360343933105469,\n",
       "  16.63965606689453,\n",
       "  -9.560343933105468,\n",
       "  -9.560343933105468,\n",
       "  -11.060343933105468,\n",
       "  -15.96034393310547,\n",
       "  -14.260343933105467,\n",
       "  -10.260343933105467,\n",
       "  -9.760343933105467,\n",
       "  -10.760343933105467,\n",
       "  -3.96034393310547,\n",
       "  -10.16034393310547,\n",
       "  -8.760343933105467,\n",
       "  -3.46034393310547,\n",
       "  3.839656066894534,\n",
       "  6.439656066894528,\n",
       "  2.839656066894534,\n",
       "  4.53965606689453,\n",
       "  -0.8603439331054688,\n",
       "  -6.96034393310547,\n",
       "  -3.7603439331054673,\n",
       "  16.63965606689453,\n",
       "  -1.3603439331054688,\n",
       "  -3.560343933105468,\n",
       "  1.5396560668945298,\n",
       "  3.6396560668945312,\n",
       "  -2.8603439331054688,\n",
       "  3.03965606689453,\n",
       "  -2.2603439331054673,\n",
       "  -4.260343933105467,\n",
       "  16.63965606689453,\n",
       "  -0.06034393310547159,\n",
       "  -3.060343933105468,\n",
       "  1.2396560668945327,\n",
       "  1.5396560668945298,\n",
       "  -0.46034393310547017,\n",
       "  -9.260343933105467,\n",
       "  8.939656066894528,\n",
       "  15.139656066894531,\n",
       "  16.63965606689453,\n",
       "  -10.760343933105467,\n",
       "  -8.96034393310547,\n",
       "  -10.860343933105469,\n",
       "  -8.96034393310547,\n",
       "  -13.360343933105469,\n",
       "  -11.66034393310547,\n",
       "  -14.060343933105468,\n",
       "  -10.96034393310547,\n",
       "  -5.260343933105467,\n",
       "  -9.66034393310547,\n",
       "  -8.360343933105469,\n",
       "  -10.060343933105468,\n",
       "  -4.6603439331054695,\n",
       "  -11.860343933105469,\n",
       "  -10.360343933105469,\n",
       "  -6.6603439331054695,\n",
       "  -11.66034393310547,\n",
       "  -5.860343933105469,\n",
       "  -3.2603439331054673,\n",
       "  11.439656066894528,\n",
       "  16.63965606689453,\n",
       "  4.239656066894533,\n",
       "  -1.7603439331054673,\n",
       "  13.339656066894534,\n",
       "  -1.8603439331054688,\n",
       "  -9.060343933105468,\n",
       "  -1.6603439331054695,\n",
       "  8.339656066894534,\n",
       "  14.939656066894528,\n",
       "  -4.360343933105469,\n",
       "  -9.360343933105469,\n",
       "  -8.260343933105467,\n",
       "  -1.8603439331054688,\n",
       "  -9.66034393310547,\n",
       "  -10.060343933105468,\n",
       "  -11.360343933105469,\n",
       "  -13.260343933105467,\n",
       "  -11.16034393310547,\n",
       "  -9.66034393310547,\n",
       "  -15.760343933105467,\n",
       "  -14.860343933105469,\n",
       "  -9.060343933105468,\n",
       "  -12.860343933105469,\n",
       "  -8.860343933105469,\n",
       "  -7.1603439331054695,\n",
       "  -8.96034393310547,\n",
       "  -8.560343933105468,\n",
       "  -3.7603439331054673,\n",
       "  9.439656066894528,\n",
       "  -11.46034393310547,\n",
       "  -12.46034393310547,\n",
       "  10.639656066894531,\n",
       "  16.63965606689453,\n",
       "  2.6396560668945312,\n",
       "  -3.2603439331054673,\n",
       "  0.4396560668945284,\n",
       "  9.739656066894533,\n",
       "  15.439656066894528,\n",
       "  -2.3603439331054688,\n",
       "  3.1396560668945312,\n",
       "  -10.560343933105468,\n",
       "  -2.6603439331054695,\n",
       "  16.63965606689453,\n",
       "  10.139656066894531,\n",
       "  -12.66034393310547,\n",
       "  -12.260343933105467,\n",
       "  -8.16034393310547,\n",
       "  -8.96034393310547,\n",
       "  1.839656066894534,\n",
       "  -0.9603439331054702,\n",
       "  -1.3603439331054688,\n",
       "  -0.1603439331054659,\n",
       "  -0.26034393310546733,\n",
       "  -4.260343933105467,\n",
       "  1.7396560668945327,\n",
       "  12.03965606689453,\n",
       "  2.03965606689453,\n",
       "  12.639656066894531,\n",
       "  16.63965606689453,\n",
       "  -1.160343933105466,\n",
       "  -11.360343933105469,\n",
       "  -13.260343933105467,\n",
       "  -10.16034393310547,\n",
       "  -11.060343933105468,\n",
       "  -8.560343933105468,\n",
       "  -4.860343933105469,\n",
       "  3.9396560668945284,\n",
       "  -5.46034393310547,\n",
       "  -9.46034393310547,\n",
       "  -11.66034393310547,\n",
       "  -4.760343933105467,\n",
       "  -6.260343933105467,\n",
       "  -13.060343933105468,\n",
       "  -10.860343933105469,\n",
       "  -4.360343933105469,\n",
       "  -8.560343933105468,\n",
       "  -11.360343933105469,\n",
       "  -6.96034393310547,\n",
       "  -0.26034393310546733,\n",
       "  2.7396560668945327,\n",
       "  -4.96034393310547,\n",
       "  0.03965606689452983,\n",
       "  -5.1603439331054695,\n",
       "  -10.560343933105468,\n",
       "  -13.060343933105468,\n",
       "  -17.260343933105467,\n",
       "  -11.260343933105467,\n",
       "  -13.96034393310547,\n",
       "  -11.760343933105467,\n",
       "  -9.560343933105468,\n",
       "  -17.16034393310547,\n",
       "  -15.560343933105468,\n",
       "  -13.560343933105468,\n",
       "  -10.260343933105467,\n",
       "  -12.360343933105469,\n",
       "  -9.560343933105468,\n",
       "  -10.260343933105467,\n",
       "  -12.96034393310547,\n",
       "  -14.860343933105469,\n",
       "  -8.360343933105469,\n",
       "  -8.760343933105467,\n",
       "  -10.360343933105469,\n",
       "  -11.16034393310547,\n",
       "  -14.060343933105468,\n",
       "  -10.760343933105467,\n",
       "  -13.560343933105468,\n",
       "  -16.260343933105467,\n",
       "  -13.96034393310547,\n",
       "  -11.16034393310547,\n",
       "  -12.66034393310547,\n",
       "  -12.260343933105467,\n",
       "  -13.860343933105469,\n",
       "  -14.860343933105469,\n",
       "  -12.760343933105467,\n",
       "  -14.360343933105469,\n",
       "  -14.66034393310547,\n",
       "  -0.6603439331054659,\n",
       "  -16.86034393310547,\n",
       "  -9.46034393310547,\n",
       "  -2.1603439331054695,\n",
       "  -15.860343933105469,\n",
       "  -16.16034393310547,\n",
       "  -10.260343933105467,\n",
       "  -8.860343933105469,\n",
       "  -6.760343933105467,\n",
       "  -10.46034393310547,\n",
       "  -9.260343933105467,\n",
       "  -14.760343933105467,\n",
       "  -3.2603439331054673,\n",
       "  -15.16034393310547,\n",
       "  -12.760343933105467,\n",
       "  -15.560343933105468,\n",
       "  -11.66034393310547,\n",
       "  -10.66034393310547,\n",
       "  -10.760343933105467,\n",
       "  -8.360343933105469,\n",
       "  -13.46034393310547,\n",
       "  -12.560343933105468,\n",
       "  -16.560343933105468,\n",
       "  -11.46034393310547,\n",
       "  -5.860343933105469,\n",
       "  -11.46034393310547,\n",
       "  -10.260343933105467,\n",
       "  16.63965606689453,\n",
       "  16.63965606689453,\n",
       "  16.63965606689453,\n",
       "  16.63965606689453,\n",
       "  16.63965606689453,\n",
       "  -19.560343933105468,\n",
       "  -19.560343933105468,\n",
       "  -18.36034393310547,\n",
       "  -19.46034393310547,\n",
       "  -20.060343933105468,\n",
       "  -20.260343933105467,\n",
       "  -23.16034393310547,\n",
       "  -22.96034393310547,\n",
       "  -22.46034393310547,\n",
       "  -22.060343933105468,\n",
       "  -21.060343933105468,\n",
       "  -24.560343933105468,\n",
       "  -26.16034393310547,\n",
       "  -22.86034393310547,\n",
       "  -25.96034393310547,\n",
       "  -23.16034393310547,\n",
       "  -21.86034393310547,\n",
       "  -18.260343933105467,\n",
       "  -10.16034393310547,\n",
       "  -23.66034393310547,\n",
       "  -19.560343933105468,\n",
       "  -20.66034393310547,\n",
       "  -20.260343933105467,\n",
       "  -20.86034393310547,\n",
       "  -24.86034393310547,\n",
       "  -28.36034393310547,\n",
       "  -27.060343933105468,\n",
       "  -27.760343933105467,\n",
       "  -26.16034393310547,\n",
       "  -21.260343933105467,\n",
       "  -25.060343933105468,\n",
       "  -24.86034393310547,\n",
       "  -28.36034393310547]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BIUU1cOZGE10"
   },
   "source": [
    "## Warming up: matrix differentiation\n",
    "_You will meet these questions later in Labs as well, so we highly recommend to answer them right here._\n",
    "\n",
    "Credits: this theoretical part is copied from [YSDA Practical_DL course](https://github.com/yandexdataschool/Practical_DL/tree/spring2019/homework01) homework01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvrZt_xNGE12"
   },
   "source": [
    "Since it easy to google every task please please please try to understand what's going on. The \"just answer\" thing will not be  counted, make sure to present derivation of your solution. It is absolutely OK if you will find an answer on web then just exercise in $\\LaTeX$ copying it into here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ty4m156yGE15"
   },
   "source": [
    "Useful links: \n",
    "[1](http://www.machinelearning.ru/wiki/images/2/2a/Matrix-Gauss.pdf)\n",
    "[2](http://www.atmos.washington.edu/~dennis/MatrixCalculus.pdf)\n",
    "[3](http://cal.cs.illinois.edu/~johannes/research/matrix%20calculus.pdf)\n",
    "[4](http://research.microsoft.com/en-us/um/people/cmbishop/prml/index.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8StFOCFGE17"
   },
   "source": [
    "#### Inline question 1\n",
    "$$  \n",
    "y = x^Tx,  \\quad x \\in \\mathbb{R}^N \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = 2x^T\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qtnNCP4JGE19"
   },
   "source": [
    "#### Inline question 2\n",
    "$$ y = tr(AB) \\quad A,B \\in \\mathbb{R}^{N \\times N} $$ \n",
    "\n",
    "$$\n",
    "\\frac{dy}{dA} = B^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWfcC7_dGE2A"
   },
   "source": [
    "#### Inline question 3\n",
    "$$  \n",
    "y = x^TAc , \\quad A\\in \\mathbb{R}^{N \\times N}, x\\in \\mathbb{R}^{N}, c\\in \\mathbb{R}^{N} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = c^TA^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dA} = xc^t\n",
    "$$\n",
    "\n",
    "Hint for the latter (one of the ways): use *ex. 2* result and the fact \n",
    "$$\n",
    "tr(ABC) = tr (CAB)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbBc_5FhGE2B"
   },
   "source": [
    "## Loss functions and derivatives implementation\n",
    "You will need to implement the methods from `loss_and_derivatives.py` to go further.\n",
    "__In this assignment we ignore the bias term__, so the linear model takes simple form of \n",
    "$$\n",
    "\\hat{\\mathbf{y}} = XW\n",
    "$$\n",
    "where no extra column of 1s is added to the $X$ matrix.\n",
    "\n",
    "Implement the loss functions, regularization terms and their derivatives with reference to (w.r.t.) weight matrix. \n",
    "\n",
    "__Once again, you can assume that linear model is not required for bias term for now. The dataset is preprocessed for this case.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-CX9dTLGE1y"
   },
   "source": [
    "Autoreload is a great stuff, but sometimes it does not work as intended. The code below aims to fix that. __Do not forget to save your changes in the `.py` file before reloading the desired functions.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtELlRTOGE2E",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# This dirty hack might help if the autoreload has failed for some reason\n",
    "try:\n",
    "    del LossAndDerivatives\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from loss_and_derivatives import LossAndDerivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mention, that in this case we compute the __MSE__ and __MAE__ for vector __y__. In the reference implementation we are averaging the error along the __y__ dimentionality as well.\n",
    "\n",
    "E.g. for residuals vector $[1., 1., 1., 1.]$ the averaged error value will be $\\frac{1}{4}(1. + 1. + 1. + 1.)$ \n",
    "\n",
    "This may be needed to get the desired mutliplier for loss functions derivatives. You also can refer to the `.mse` method implementation, which is already available in the `loss_and_derivatives.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71VCxUwHGE2L"
   },
   "outputs": [],
   "source": [
    "w = np.array([1., 1.])\n",
    "x_n, y_n = feature_matrix, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMN81aYyGE2T"
   },
   "source": [
    "Here come several asserts to check yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKUYnPWuGE2V"
   },
   "outputs": [],
   "source": [
    "w = np.array([1., 1.])\n",
    "x_n, y_n = feature_matrix, targets\n",
    "\n",
    "# Repeating data to make everything multi-dimentional\n",
    "w = np.vstack([w[None, :] + 0.27, w[None, :] + 0.22, w[None, :] + 0.45, w[None, :] + 0.1]).T\n",
    "y_n = np.hstack([y_n[:, None], 2*y_n[:, None], 3*y_n[:, None], 4*y_n[:, None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.27, 1.22, 1.45, 1.1 ],\n",
       "       [1.27, 1.22, 1.45, 1.1 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1344,
     "status": "error",
     "timestamp": 1582397124081,
     "user": {
      "displayName": "Victor Yacovlev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDahDnBQR6_kQQX4xt7llKTI0xt2Z802bvVR4MrqA=s64",
      "userId": "11689260236152306260"
     },
     "user_tz": -180
    },
    "id": "UtkO4hWYGE2c",
    "outputId": "cb0b99a8-2db4-4873-dfd8-741b52db29f3"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m reference_mse_derivative \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     [ \u001b[39m7.32890068\u001b[39m, \u001b[39m12.88731311\u001b[39m, \u001b[39m18.82128365\u001b[39m, \u001b[39m23.97731238\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     [ \u001b[39m9.55674399\u001b[39m, \u001b[39m17.05397661\u001b[39m, \u001b[39m24.98807528\u001b[39m, \u001b[39m32.01723714\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m reference_l2_reg_derivative \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [\u001b[39m2.54\u001b[39m, \u001b[39m2.44\u001b[39m, \u001b[39m2.9\u001b[39m , \u001b[39m2.2\u001b[39m ],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     [\u001b[39m2.54\u001b[39m, \u001b[39m2.44\u001b[39m, \u001b[39m2.9\u001b[39m , \u001b[39m2.2\u001b[39m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39;49mallclose(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     reference_mse_derivative,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     LossAndDerivatives\u001b[39m.\u001b[39;49mmse_derivative(x_n, y_n, w), rtol\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m ), \u001b[39m'\u001b[39m\u001b[39mSomething wrong with MSE derivative\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mallclose(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     reference_l2_reg_derivative,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     LossAndDerivatives\u001b[39m.\u001b[39ml2_reg_derivative(w), rtol\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m ), \u001b[39m'\u001b[39m\u001b[39mSomething wrong with L2 reg derivative\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMSE derivative:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mL2 reg derivative:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         LossAndDerivatives\u001b[39m.\u001b[39mmse_derivative(x_n, y_n, w),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         LossAndDerivatives\u001b[39m.\u001b[39ml2_reg_derivative(w))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X24sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m )\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numeric.py:2251\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[1;32m   2181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mallclose\u001b[39m(a, b, rtol\u001b[39m=\u001b[39m\u001b[39m1.e-5\u001b[39m, atol\u001b[39m=\u001b[39m\u001b[39m1.e-8\u001b[39m, equal_nan\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   2182\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2183\u001b[0m \u001b[39m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[1;32m   2184\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2249\u001b[0m \n\u001b[1;32m   2250\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2251\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(isclose(a, b, rtol\u001b[39m=\u001b[39;49mrtol, atol\u001b[39m=\u001b[39;49matol, equal_nan\u001b[39m=\u001b[39;49mequal_nan))\n\u001b[1;32m   2252\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(res)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numeric.py:2359\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2356\u001b[0m     y \u001b[39m=\u001b[39m asanyarray(y, dtype\u001b[39m=\u001b[39mdt)\n\u001b[1;32m   2358\u001b[0m xfin \u001b[39m=\u001b[39m isfinite(x)\n\u001b[0;32m-> 2359\u001b[0m yfin \u001b[39m=\u001b[39m isfinite(y)\n\u001b[1;32m   2360\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(xfin) \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(yfin):\n\u001b[1;32m   2361\u001b[0m     \u001b[39mreturn\u001b[39;00m within_tol(x, y, atol, rtol)\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "reference_mse_derivative = np.array([\n",
    "    [ 7.32890068, 12.88731311, 18.82128365, 23.97731238],\n",
    "    [ 9.55674399, 17.05397661, 24.98807528, 32.01723714]\n",
    "])\n",
    "reference_l2_reg_derivative = np.array([\n",
    "    [2.54, 2.44, 2.9 , 2.2 ],\n",
    "    [2.54, 2.44, 2.9 , 2.2 ]\n",
    "])\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_mse_derivative,\n",
    "    LossAndDerivatives.mse_derivative(x_n, y_n, w), rtol=1e-3\n",
    "), 'Something wrong with MSE derivative'\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_l2_reg_derivative,\n",
    "    LossAndDerivatives.l2_reg_derivative(w), rtol=1e-3\n",
    "), 'Something wrong with L2 reg derivative'\n",
    "\n",
    "print(\n",
    "    'MSE derivative:\\n{} \\n\\nL2 reg derivative:\\n{}'.format(\n",
    "        LossAndDerivatives.mse_derivative(x_n, y_n, w),\n",
    "        LossAndDerivatives.l2_reg_derivative(w))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m reference_mae_derivative \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     [\u001b[39m0.19708867\u001b[39m, \u001b[39m0.19621798\u001b[39m, \u001b[39m0.19621798\u001b[39m, \u001b[39m0.19572906\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     [\u001b[39m0.25574138\u001b[39m, \u001b[39m0.25524507\u001b[39m, \u001b[39m0.25524507\u001b[39m, \u001b[39m0.25406404\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m reference_l1_reg_derivative \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     [\u001b[39m1.\u001b[39m, \u001b[39m1.\u001b[39m, \u001b[39m1.\u001b[39m, \u001b[39m1.\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     [\u001b[39m1.\u001b[39m, \u001b[39m1.\u001b[39m, \u001b[39m1.\u001b[39m, \u001b[39m1.\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39;49mallclose(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     reference_mae_derivative,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     LossAndDerivatives\u001b[39m.\u001b[39;49mmae_derivative(x_n, y_n, w), rtol\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m ), \u001b[39m'\u001b[39m\u001b[39mSomething wrong with MAE derivative\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mallclose(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     reference_l1_reg_derivative,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     LossAndDerivatives\u001b[39m.\u001b[39ml1_reg_derivative(w), rtol\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m ), \u001b[39m'\u001b[39m\u001b[39mSomething wrong with L1 reg derivative\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMAE derivative:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mL1 reg derivative:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         LossAndDerivatives\u001b[39m.\u001b[39mmae_derivative(x_n, y_n, w),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         LossAndDerivatives\u001b[39m.\u001b[39ml1_reg_derivative(w))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X25sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m )\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numeric.py:2251\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[1;32m   2181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mallclose\u001b[39m(a, b, rtol\u001b[39m=\u001b[39m\u001b[39m1.e-5\u001b[39m, atol\u001b[39m=\u001b[39m\u001b[39m1.e-8\u001b[39m, equal_nan\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   2182\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2183\u001b[0m \u001b[39m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[1;32m   2184\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2249\u001b[0m \n\u001b[1;32m   2250\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2251\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(isclose(a, b, rtol\u001b[39m=\u001b[39;49mrtol, atol\u001b[39m=\u001b[39;49matol, equal_nan\u001b[39m=\u001b[39;49mequal_nan))\n\u001b[1;32m   2252\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(res)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numeric.py:2359\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2356\u001b[0m     y \u001b[39m=\u001b[39m asanyarray(y, dtype\u001b[39m=\u001b[39mdt)\n\u001b[1;32m   2358\u001b[0m xfin \u001b[39m=\u001b[39m isfinite(x)\n\u001b[0;32m-> 2359\u001b[0m yfin \u001b[39m=\u001b[39m isfinite(y)\n\u001b[1;32m   2360\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(xfin) \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(yfin):\n\u001b[1;32m   2361\u001b[0m     \u001b[39mreturn\u001b[39;00m within_tol(x, y, atol, rtol)\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "reference_mae_derivative = np.array([\n",
    "    [0.19708867, 0.19621798, 0.19621798, 0.19572906],\n",
    "    [0.25574138, 0.25524507, 0.25524507, 0.25406404]\n",
    "])\n",
    "reference_l1_reg_derivative = np.array([\n",
    "    [1., 1., 1., 1.],\n",
    "    [1., 1., 1., 1.]\n",
    "])\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_mae_derivative,\n",
    "    LossAndDerivatives.mae_derivative(x_n, y_n, w), rtol=1e-3\n",
    "), 'Something wrong with MAE derivative'\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_l1_reg_derivative,\n",
    "    LossAndDerivatives.l1_reg_derivative(w), rtol=1e-3\n",
    "), 'Something wrong with L1 reg derivative'\n",
    "\n",
    "print(\n",
    "    'MAE derivative:\\n{} \\n\\nL1 reg derivative:\\n{}'.format(\n",
    "        LossAndDerivatives.mae_derivative(x_n, y_n, w),\n",
    "        LossAndDerivatives.l1_reg_derivative(w))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJcSPj8UGE20"
   },
   "source": [
    "### Gradient descent on the real data\n",
    "Here comes small loop with gradient descent algorithm. We compute the gradient over the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "On6aSWuIGE21"
   },
   "outputs": [],
   "source": [
    "def get_w_by_grad(X, Y, w_0, loss_mode='mse', reg_mode=None, lr=0.05, n_steps=100, reg_coeff=0.05):\n",
    "    if loss_mode == 'mse':\n",
    "        loss_function = LossAndDerivatives.mse\n",
    "        loss_derivative = LossAndDerivatives.mse_derivative\n",
    "    elif loss_mode == 'mae':\n",
    "        loss_function = LossAndDerivatives.mae\n",
    "        loss_derivative = LossAndDerivatives.mae_derivative\n",
    "    else:\n",
    "        raise ValueError('Unknown loss function. Available loss functions: `mse`, `mae`')\n",
    "    \n",
    "    if reg_mode is None:\n",
    "        reg_function = LossAndDerivatives.no_reg\n",
    "        reg_derivative = LossAndDerivatives.no_reg_derivative # lambda w: np.zeros_like(w)\n",
    "    elif reg_mode == 'l2':\n",
    "        reg_function = LossAndDerivatives.l2_reg\n",
    "        reg_derivative = LossAndDerivatives.l2_reg_derivative\n",
    "    elif reg_mode == 'l1':\n",
    "        reg_function = LossAndDerivatives.l1_reg\n",
    "        reg_derivative = LossAndDerivatives.l1_reg_derivative\n",
    "    else:\n",
    "        raise ValueError('Unknown regularization mode. Available modes: `l1`, `l2`, None')\n",
    "    \n",
    "    \n",
    "    w = w_0.copy()\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        empirical_risk = loss_function(X, Y, w) + reg_coeff * reg_function(w)\n",
    "        gradient = loss_derivative(X, Y, w) + reg_coeff * reg_derivative(w)\n",
    "        gradient_norm = np.linalg.norm(gradient)\n",
    "        if gradient_norm > 5.:\n",
    "            gradient = gradient / gradient_norm * 5.\n",
    "        w -= lr * gradient\n",
    "        \n",
    "        if i % 25 == 0:\n",
    "            print('Step={}, loss={},\\ngradient values={}\\n'.format(i, empirical_risk, gradient))\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1pyDIyqGE25"
   },
   "outputs": [],
   "source": [
    "# Initial weight matrix\n",
    "w = np.ones((2,1), dtype=float)\n",
    "y_n = targets[:, None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erTRQiAFGE29"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m w_grad \u001b[39m=\u001b[39m get_w_by_grad(x_n, y_n, w, loss_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmse\u001b[39;49m\u001b[39m'\u001b[39;49m, reg_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ml2\u001b[39;49m\u001b[39m'\u001b[39;49m, n_steps\u001b[39m=\u001b[39;49m\u001b[39m250\u001b[39;49m)\n",
      "\u001b[1;32m/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb Cell 26\u001b[0m in \u001b[0;36mget_w_by_grad\u001b[0;34m(X, Y, w_0, loss_mode, reg_mode, lr, n_steps, reg_coeff)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X33sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_steps):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X33sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     empirical_risk \u001b[39m=\u001b[39m loss_function(X, Y, w) \u001b[39m+\u001b[39m reg_coeff \u001b[39m*\u001b[39m reg_function(w)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X33sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     gradient \u001b[39m=\u001b[39m loss_derivative(X, Y, w) \u001b[39m+\u001b[39m reg_coeff \u001b[39m*\u001b[39;49m reg_derivative(w)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X33sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     gradient_norm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(gradient)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jctuesta/Documents/ML/ml-course/homeworks_basic/assignment0_02_Lin_reg/assignment0_02_linear_regression_and_GD.ipynb#X33sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mif\u001b[39;00m gradient_norm \u001b[39m>\u001b[39m \u001b[39m5.\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "w_grad = get_w_by_grad(x_n, y_n, w, loss_mode='mse', reg_mode='l2', n_steps=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with `sklearn`\n",
    "Finally, let's compare our model with `sklearn` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Ridge(alpha=0.05)\n",
    "lr.fit(x_n, y_n)\n",
    "print('sklearn linear regression implementation delivers MSE = {}'.format(np.mean((lr.predict(x_n) - y_n)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gse1m4nyGE3C"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x_n[:, -1], y_n[:, -1])\n",
    "plt.scatter(x_n[:, -1], x_n.dot(w_grad)[:, -1], color='orange', label='Handwritten linear regression', linewidth=5)\n",
    "plt.scatter(x_n[:, -1], lr.predict(x_n), color='cyan', label='sklearn Ridge')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the solutions may look like a bit different, remember, that handwritten linear regression was unable to fit the bias term, it was equal to $0$ by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GgeWdBmGE3H"
   },
   "source": [
    "### Submit your work\n",
    "To submit your work you need to log into Yandex contest (link will be provided later) and upload the `loss_and_derivatives.py` file for the corresponding problem."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment0_02_linear_regression_and_gradient_descent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
