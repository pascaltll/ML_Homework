{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework02: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "P8zS7m-gycN5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import tqdm\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5mfBIbOrw6L"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "B7C8xNegrw6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6644400-01ac-49eb-fcca-e14f1120185e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    17    0    17    0     0     78      0 --:--:-- --:--:-- --:--:--    78\n",
            "100   342  100   342    0     0    661      0 --:--:-- --:--:-- --:--:--   661\n",
            "100  119M  100  119M    0     0  56.2M      0  0:00:02  0:00:02 --:--:--  138M\n",
            "Train_rev1.csv\n"
          ]
        }
      ],
      "source": [
        "# uncomment and run this cell, if you don't have data locally yet.\n",
        "\n",
        "!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
        "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vwN72gd4ycOA"
      },
      "outputs": [],
      "source": [
        "# run this cell if you have downloaded the dataset on the seminar\n",
        "#data = pd.read_csv(\"../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv\", index_col=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UuuKIKfrycOH"
      },
      "outputs": [],
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)\n",
        "\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RUWkpd7PycOQ",
        "outputId": "39876f8d-3282-40f2-f100-d82b7f015a2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "239768it [00:26, 9043.80it/s] \n"
          ]
        }
      ],
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "# see task above\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "token_counts = Counter()# <YOUR CODE HERE>\n",
        "for _, row in tqdm(data[text_columns].iterrows()):\n",
        "    for string in row:\n",
        "        token_counts.update(string.split())\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Gb3Bl3Eprw6N",
        "outputId": "146b22f6-7fa1-4429-a1f3-63d2bfe45051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2598827"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "token_counts.most_common(1)[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiOWbc15ycOb",
        "outputId": "d41aa097-e13a-4ded-9c96-b8acf0de9c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 201127\n",
            "('and', 2598827)\n",
            "('.', 2471477)\n",
            "(',', 2266256)\n",
            "('the', 2036428)\n",
            "('to', 1977039)\n",
            "...\n",
            "('dbms_stats', 1)\n",
            "('dbms_output', 1)\n",
            "('dbms_job', 1)\n",
            "Correct!\n",
            "Vocabulary size: 33795\n",
            "Correct!\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')\n",
        "\n",
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JEsLeBjVycOw"
      },
      "outputs": [],
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBlPkdKycOy",
        "outputId": "7d0456d6-3225-4cac-f78c-786ffc6461c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10705 29830  2143     1     1]\n",
            " [14875  2817     1     1     1]\n",
            " [27345 10107    15 15069 10702]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "DpOlBp7ZycO6",
        "outputId": "402ea47a-af7c-421e-8cb7-d9bd1a97332a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX67GlsJGdAv",
        "outputId": "57b57c60-6c4d-46d7-f713-cf9c3b32892b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngLcWA0ycO_",
        "outputId": "3367d2dc-2977-4f89-a527-197650a6bfea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2PXuKgOSycPB"
      },
      "outputs": [],
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "I6LpEQf0ycPD"
      },
      "outputs": [],
      "source": [
        "a = make_batch(data_train[:3], max_len=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS6aGHiWrw6P"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "S6S7_iLBrw6Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "t3mtREgvrw6Q"
      },
      "outputs": [],
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy-B3xyYrw6Q"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "THAES28prw6Q"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "j0X-pCSgrw6Q"
      },
      "outputs": [],
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "I5hBW4S2rw6Q"
      },
      "outputs": [],
      "source": [
        "# Here is some startup code:\n",
        "n_tokens=len(tokens)\n",
        "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
        "hid_size=64\n",
        "simple_model = nn.Sequential()\n",
        "\n",
        "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
        "simple_model.add_module('reorder', Reorder())\n",
        "simple_model.add_module('conv1', nn.Conv1d(\n",
        "    in_channels=hid_size,\n",
        "    out_channels=hid_size,\n",
        "    kernel_size=2)\n",
        "                       )\n",
        "simple_model.add_module('relu1', nn.ReLU())\n",
        "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
        "simple_model.add_module('flatten1', Flatten())\n",
        "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "xxX7ab2jrw6R",
        "outputId": "e90b3491-528f-4a46-983b-485030402e58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Title': array([[27345, 32512, 23971, 10702,     1],\n",
              "        [18986, 30077,  2817,     1,     1],\n",
              "        [17487, 12023, 27445, 10702, 23405]], dtype=int32),\n",
              " 'FullDescription': array([[27345, 32512, 23971, 10702,     0, 30762,  1303,  2662, 30411,\n",
              "         17041, 30131, 17567, 33209, 30411, 22977,  2546, 21405,  5601,\n",
              "         32512, 18776,   167, 27479, 31823,  2166,  5872, 21405, 20697,\n",
              "         23975,   195, 30842, 33209,     0,  2546,   167, 21590,  5872,\n",
              "          2166, 31362, 21405, 11390, 23975,   167, 27229, 21405, 19439,\n",
              "         30762,  1235, 30411,  1059,   167, 15150,  2166, 25204, 21405,\n",
              "          8631,  2840, 33198, 30411,     0,  2546,  2166,  9079,  2166,\n",
              "         28344, 21405, 24002,   195, 33604, 23956, 24257, 21405, 30131,\n",
              "         29566, 30762, 17932, 10705,  8664,   195, 14601, 15402,   965,\n",
              "         22994, 26982,   167,   692, 33591, 11453, 21405, 22977, 15402,\n",
              "           965, 32512, 23976, 11667,   167, 11453, 21405,     0,  2166,\n",
              "          3108, 32512,  6509,   195,  8992, 29830,   167, 15143, 11453,\n",
              "         21556,     0, 21784,     0,     0, 30512, 16658, 32637, 21870,\n",
              "         23459,  2662, 33468,   167, 30895,   167,  6681,   195, 16679,\n",
              "           195,     0,    80,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1],\n",
              "        [18986, 13520, 29841, 26324,  2545, 33635,   965, 25009, 13520,\n",
              "         33198,   965,   124,   262, 21784,   432,  6261,  8664, 15402,\n",
              "         18986,   156, 18235, 30762, 12961, 11453, 15402,   965, 26977,\n",
              "         30762, 29566,  2166,  4299, 33642,  2386, 12466,   965, 22902,\n",
              "         21784, 13741,   927,  9526, 33635, 14109,   965,  5196,  9526,\n",
              "          2985,  2166, 30411,  8913,  2166, 22405, 30762, 29566,    80,\n",
              "         33585, 21514, 15402, 30411,  9000, 21405, 30422, 28004,  2166,\n",
              "          1041, 17768,   927, 32637, 33642,  8664, 18986,  3512,  2166,\n",
              "          9526, 33635, 14109,   965, 29227,  1099, 25078,   927, 30512,\n",
              "         16289, 30411, 16658, 12466, 33635,   167, 15142, 23130, 12466,\n",
              "         24201, 22902,   195, 13741, 29257,   262, 33585,  7338, 10039,\n",
              "         31823, 30762,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1],\n",
              "        [21972,  6347, 16289, 30411, 17441, 15700, 17487, 24249, 15402,\n",
              "         30411, 31523, 16262,   167, 30487,  2545,  8091, 25110, 12466,\n",
              "           965, 17487, 12023, 27445, 10702, 23405, 30762, 25618, 18581,\n",
              "         17487, 27956,  2166, 10944,   167, 33635, 20357, 14109, 29227,\n",
              "           156,  8753, 10364,  2166, 19197, 10705, 11453,    32, 33198,\n",
              "          2451, 24556,    63, 15143, 12769,   965,  6739, 27445,  3268,\n",
              "         21784, 32988, 13451,   195,  5538,   156, 14860,  2385, 12769,\n",
              "           965,  9580,  3268,  2545,  1973, 32817, 30762,  2395,   167,\n",
              "         33635, 20357, 14109,   965, 29227, 30131, 19640,  7651, 33198,\n",
              "         30411,  1041, 30762,  8756,  2120, 31641, 21405, 30411, 17487,\n",
              "         12023, 27445, 10702,    18, 26612, 26324,   167,  3512, 15402,\n",
              "         23405,   156, 33635, 33079,  3607,  2120,  2026, 12466, 30411,\n",
              "          6835,   156, 25623, 10944,   195, 18590, 27956,  2166, 21419,\n",
              "         23954, 28362, 23574,  1560,   156, 32976, 24253, 11295,  1650,\n",
              "         26684,  8114, 27445,  2166,  5333,   167, 30411, 29406,  2384,\n",
              "         33079, 23433,  1894, 21405, 30411,  1059,   156,  3607, 24390,\n",
              "          2166, 25481, 33198,   965, 29227, 27382, 21405, 23954, 28362,\n",
              "           156, 25864,  2166, 22129,   167, 11068, 25729,  2545,   891,\n",
              "         14600, 19674, 21784, 10958, 33209, 10364, 10705,  8753, 12023,\n",
              "         27445, 11453,  8753, 11453, 21405, 11838, 12122, 21556,  4353,\n",
              "         27920,  2166,    80, 22925, 32799, 33331, 26409, 16289,   262,\n",
              "         32799, 15402,    80,  2395, 21133, 12466, 30411, 17487, 12023,\n",
              "         27445, 10702, 23405,  5016, 27342, 33642,  8167, 33198,  7682,\n",
              "         17747, 30762, 13357,   167,  6681, 24668, 25239, 13380,   115,\n",
              "         30512, 16658, 32637, 21870, 23459,  2662, 33468,   167, 30895,\n",
              "           167,  6681,   195, 16679,   195,     0,    80]], dtype=int32),\n",
              " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju4qU-T_rw6R"
      },
      "source": [
        "__Remember!__ We are working with regression problem and predicting only one number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "iSGnXd5crw6R",
        "outputId": "aa415bc0-f8a2-48f5-8258-05b4ab07af0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0794],\n",
              "        [ 0.1220],\n",
              "        [-0.0881]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
        "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "KZ44Ore5rw6R",
        "outputId": "84393a9f-f268-4ff4-ac46-93bc36a0afd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 232)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "batch['FullDescription'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMLHBxKPrw6R"
      },
      "source": [
        "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "yPajm1IIrw6R",
        "outputId": "72047e96-008d-475c-f854-6b35399c1905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = simple_model\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "         # Preprocessing the batch data and target\n",
        "         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
        "\n",
        "         target = torch.tensor(target)\n",
        "\n",
        "\n",
        "         predictions = model(batch)\n",
        "         predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "         # train with backprop\n",
        "         loss.backward()\n",
        "         opt.step()\n",
        "         opt.zero_grad()\n",
        "         # <YOUR CODE HERE>\n",
        "\n",
        "         history.append(loss.data.numpy())\n",
        "         if (idx+1)%10==0:\n",
        "             clear_output(True)\n",
        "             plt.plot(history,label='loss')\n",
        "             plt.legend()\n",
        "             plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLVPSyAGrw6S"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "TFGp74whrw6S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "cbeba3f4-9f75-4713-8eda-0aea69688a27"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-05ef27a3bbcc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'network'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GctfplB4rw6S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "83a679ca-3485-4293-da7a-80a596a027b9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-07e207755284>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Re-run this cell if you updated the file with network source code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'network' is not defined"
          ]
        }
      ],
      "source": [
        "# Re-run this cell if you updated the file with network source code\n",
        "import imp\n",
        "imp.reload(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A1SDi5drw6S"
      },
      "outputs": [],
      "source": [
        "model = network.ThreeInputsNet(\n",
        "    n_tokens=len(tokens),\n",
        "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
        "\n",
        "    # this parameter defines the number of the inputs in the layer,\n",
        "    # which stands after the concatenation. In should be found out by you.\n",
        "    concat_number_of_features=<YOUR CODE HERE> \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6o_9K84rw6S"
      },
      "outputs": [],
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['Categorical'])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THSGNqltrw6S"
      },
      "outputs": [],
      "source": [
        "assert model(testing_batch).shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMEost9Nrw6S"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DxPD3djrw6T"
      },
      "outputs": [],
      "source": [
        "# Training pipeline comes here (almost the same as for the simple_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3hGYCcUrw6T"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elTipsberw6W"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExdhpMoqrw6W"
      },
      "outputs": [],
      "source": [
        "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    output_list = []\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['Categorical'])\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eh0DzAmirw6W"
      },
      "outputs": [],
      "source": [
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC3bFBOBrw6W"
      },
      "source": [
        "__Both the notebook and the `.py` file are required to submit this homework.__"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}